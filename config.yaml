# dataset
dataset:
  # csv format, source_speaker_index must be < n_speakers
  # mixture_path, source_path, length, source_speaker, source_speaker_index
  train: 'audio/csv/test.csv'
  # source_path, length, source_speaker, source_speaker_index
  train_enroll: 'audio/csv/train_enr.csv'
  valid: 'audio/csv/valid.csv'
  valid_enroll: 'audio/csv/valid_enr.csv'
  test: 'audio/csv/valid.csv'
  test_enroll: 'audio/csv/valid_enr.csv'

# training parameters
train:
  max_epochs: 10
  gradient_clip_val: 5.
  precision: 16
  accelerator: 'gpu'
  batch_size: 1
  learning_rate: 1.e-4
  sample_rate: 16000
  segment: 3
  output: ./output/model.pt
  logdir: ./logs
# sepformer parameters
sepformer:
  # positional encoding
  max_len: 80000
  # encoder/decoder conv filters
  channels: 256 #128
  kernel_size: 16
  stride: 8
  # chunking samples
  chunk_size: 250
  # intra- & inter- Transformers
  d_model: 256 #128
  nhead: 8
  dim_feedforward: 1024
  layer_norm_eps: 1.e-8
  num_layers: 8 #4
  # sepformers
  num_sepformer_layers: 2 #1
  # speakers
  num_speakers: 307
  # dropout (all modules)
  dropout: 0.1
  lambda1: 1.0
  lambda2: 1.0
tasnet:
  kernel_size: 20
  in_channels: 256
  enc_channels: 256
  conv_channels: 512
  num_blocks: 8
  block_kernel_size: 3
  num_repeats: 4
  num_speakers: 256
diffusion:
  timesteps: 200
  beta_start: 0.001
  beta_end: 0.02
  lambda1: 1.0
  lambda2: 1.0
unet:
  normalize: True
  floor: 1e-3
  resample: 4
  depth: 5
  in_channels: 1
  mid_channels: 48
  out_channels: 1
  max_channels: 10000
  kernel_size: 8
  growth: 2
  rescale: 0.1
  stride: 4
  reference: 0.1
  causal: True