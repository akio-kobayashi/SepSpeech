# dataset
dataset:
  # csv format, source_speaker_index must be < n_speakers
  # mixture_path, source_path, length, source_speaker, source_speaker_index
  train: ''
  # source_path, length, source_speaker, source_speaker_index
  train_enroll: ''
  valid: ''
  valid_enroll: ''
  test: ''
  test_enroll: ''

# training parameters
train:
  max_epochs: 100
  gradient_clip_val: 5.
  precision: 16
  accelerator: 'gpu'
  batch_size: 16
  sample_rate: 16000
  segment: 3

# sepformer parameters
sepformer:
  # positional encoding
  max_len: 80000
  # encoder/decoder conv filters
  channels: 128 #256
  kernel_size: 16
  stride: 8
  # chunking samples
  chunk_size: 250
  # intra- & inter- Transformers
  d_model: 128 #256
  nhead: 8
  dim_feedforward: 1024
  layer_norm_eps: 1.e-8
  num_layers: 4 #8
  # sepformers
  num_sepformer_layers: 1 #2
  # speakers
  num_speakers: 256
  # dropout (all modules)
  dropout: 0.1
tasnet:
  kernel_size: 20
  in_channels: 256
  enc_channels: 256
  conv_channels: 512
  num_blocks: 8
  block_kernel_size: 3
  num_repeats: 4
  num_speakers: 256
diffusion:
  timesteps: 200
  beta_start: 0.001
  beta_end: 0.02
  lambda1: 1.0
  lambda2: 1.0
unet:
  normalize: True
  floor: 1e-3
  resample: 4
  depth: 5
  in_channels: 1
  mid_channels: 48
  out_channels: 1
  max_channels: 10000
  kernel_size: 8
  growth: 2
  rescale: 0.1
  stride: 4
  reference: 0.1
  causal: True